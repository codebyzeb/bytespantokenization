#!/bin/bash -l

# SLURM configuration
#SBATCH --nodes=1             # This needs to match Trainer(num_nodes=...)
#SBATCH --ntasks-per-node=4   # This needs to match Trainer(devices=...)
#SBATCH --gres=gpu:4
#SBATCH --time=0-31:00:00
#SBATCH --account BUTTERY-SL2-GPU
#SBATCH --partition ampere
#SBATCH --signal=SIGUSR1@120
#SBATCH --job-name=info-tok  # <- change model here
#SBATCH --mail-type=ALL
#SBATCH --output=/rds/user/zg258/hpc-work/infotokenization/outputs/fw57M-tied/slurm_%j.out  # <- change model here
#SBATCH --error=/rds/user/zg258/hpc-work/infotokenization/outputs/fw57M-tied/slurm_%j.err   # <- change model here
#SBATCH --open-mode=append
#SBATCH --exclusive

model=fw57M-tied # <- change model here

# Debugging flags (optional)
export NCCL_DEBUG=WARN
export PYTHONFAULTHANDLER=1
export CUDA_LAUNCH_BLOCKING=0
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"

# Environment setup
echo -e 'loading other modules'
. /etc/profile.d/modules.sh  # Leave this line (enables the module command)
module list
module purge  # Removes all modules still loaded
module load rhel8/default-amp
module load cuda/12.1
module load cudnn/8.9_cuda-12.1
module list

source .venv/bin/activate
uv sync

# Run script
srun uv run scripts/train.py \
    +callbacks.grad_accum.scheduling="{0: 1}" \
    data.eval_batch_size=128 \
    model=$model \
    pwd=/home/zg258/rds/hpc-work/infotokenization \
    torch_compile=true \
    trainer.devices=4 \
    data.num_workers=12 \
    hydra.run.dir=outputs/$model \
    run_folder=. \
    resume_from_checkpoint=.checkpoints/last.ckpt \
    tok_name=bytelevel

# sintr -A VLACHOS-SL3-GPU -p ampere -t 1:0:0 --qos=INTR --gres gpu:4
# squeue -u pl487
# scontrol update job=5373629 JobName=1B
# sintr -A VLACHOS-SL3-CPU -p icelake -t 1:0:0 --qos=INTR --exclusive
# scancel 6894708